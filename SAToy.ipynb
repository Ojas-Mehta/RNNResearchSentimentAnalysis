{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SAToy.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ojas-Mehta/RNNResearchSentimentAnalysis/blob/master/SAToy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSqiB0jwQcgr",
        "colab_type": "code",
        "outputId": "d360d4c1-c7ef-40c2-c4cf-e213ae2f5295",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po1TptY8WhBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pickle\n",
        "import json\n",
        "import pandas as pd\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUTzBcALhpn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# ########Generate synthetic data\n",
        "#torch.manual_seed(2109)\n",
        "# #train_synth.csv, test_synth.csv\n",
        "# import numpy as np\n",
        "# import csv\n",
        "# dataset = []\n",
        "# dataset_size = 2000\n",
        "# for i in range(dataset_size):\n",
        "#     a = np.floor(100*np.random.rand(10)).astype(int)\n",
        "#     if(((80 <= a) & (a < 89)).sum()>=((90 <= a) & (a < 100)).sum()):\n",
        "#       label = 1\n",
        "#     else:\n",
        "#       label = 0\n",
        "#     dataset.append([a.tolist(),label])\n",
        "# with open('/content/drive/My Drive/sentiment/data/val_small.csv', 'w') as csvFile:\n",
        "#     writer = csv.writer(csvFile)\n",
        "#     writer.writerows(dataset)\n",
        "# csvFile.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBJ39LSkBZ6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Read data\n",
        "#Train = 15000, Val = 2000, Test = 3000\n",
        "train_data = pd.read_csv('sentiment/data/train_small.csv', header = None)\n",
        "val_data = pd.read_csv('sentiment/data/val_small.csv', header = None)\n",
        "test_data = pd.read_csv('sentiment/data/test_small.csv', header = None)\n",
        "train_X_list = train_data[0].tolist()\n",
        "train_y = train_data[1].tolist()\n",
        "val_X_list = val_data[0].tolist()\n",
        "val_y = val_data[1].tolist()\n",
        "test_X_list = test_data[0].tolist()\n",
        "test_y = test_data[1].tolist()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRFfV-AUybLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preprocesssing:String to Numeric\n",
        "torch.manual_seed(2109)\n",
        "def stringToList(string):\n",
        "    string = string[1:len(string)-1]\n",
        "    try:\n",
        "        if len(string) != 0: \n",
        "            tempList = string.split(\", \")\n",
        "            newList = list(map(lambda x: int(x), tempList))\n",
        "        else:\n",
        "            newList = []\n",
        "    except:\n",
        "        newList = [-9999]\n",
        "    return(newList)\n",
        "train_X_list = [stringToList(x) for x in train_X_list]\n",
        "train_X = torch.tensor(train_X_list, dtype=torch.long)\n",
        "val_X_list = [stringToList(x) for x in val_X_list]\n",
        "val_X = torch.tensor(val_X_list, dtype=torch.long)\n",
        "test_X_list = [stringToList(x) for x in test_X_list]\n",
        "test_X = torch.tensor(test_X_list, dtype=torch.long)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWGMDRiZCLI1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31c5c3cb-2687-4859-e934-d5382680712b"
      },
      "source": [
        "len(test_X_list)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjl6NLFQfK38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define hyperparameters\n",
        "input_dim = 10\n",
        "output_dim = 2\n",
        "n_epochs = 150\n",
        "batch_size = 100\n",
        "lr = 0.001\n",
        "hidden_dimension = 8\n",
        "patience_param = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXizYy5pjKxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get embeddings for data\n",
        "torch.manual_seed(2109)\n",
        "embeddings = nn.Embedding(100, input_dim)\n",
        "train_input = embeddings(train_X)\n",
        "train_output = torch.tensor(train_y, dtype=torch.long)\n",
        "\n",
        "val_input = embeddings(val_X)\n",
        "val_output = torch.tensor(val_y, dtype=torch.long)\n",
        "test_input = embeddings(test_X)\n",
        "result = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-LmbDMhdZ0z",
        "colab_type": "code",
        "outputId": "250cbb0c-ca00-468a-a581-8d859fbc6a33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "#########Inference from the saved model\n",
        "batch_size = 15000\n",
        "def evaluate(tempmodel, dataX, dataY, criterion, batch_size):\n",
        "  \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    correct_pred = 0\n",
        "    tempmodel.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, dataX.shape[0], batch_size):\n",
        "            batchX, batchy = dataX[i:i+batch_size], dataY[i:i+batch_size]\n",
        "            batchX = batchX.to(device)\n",
        "            batchy = batchy.to(device)\n",
        "            output, hidden = tempmodel(batchX, batch_size = batch_size)          \n",
        "            loss = criterion(hidden, batchy)\n",
        "\n",
        "            epoch_loss += loss.item()*batch_size\n",
        "            _, predicted_labels = torch.max(hidden, 1)\n",
        "            correct_pred += (predicted_labels==batchy).sum().item()\n",
        "        accuracy = correct_pred/ len(dataX)*100\n",
        "        epoch_loss /= len(dataX)   \n",
        "    return epoch_loss, accuracy\n",
        "is_cuda = torch.cuda.is_available()\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")\n",
        "    \n",
        "    \n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers, batch_size):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "\n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "    \n",
        "    def forward(self, x, batch_size):\n",
        "        \n",
        "        hidden = self.init_hidden(batch_size)\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "\n",
        "        hidden = hidden.transpose(0,1).contiguous().view(batch_size, -1)\n",
        "        hidden = self.fc(hidden)\n",
        "        return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
        "        hidden = hidden.to(device)\n",
        "        return hidden\n",
        "\n",
        "# Define Loss, Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# Create and Load the model\n",
        "batch_size = 15000\n",
        "model = Model(input_size=input_dim, output_size=output_dim, hidden_dim=hidden_dimension, n_layers=1, batch_size = batch_size)\n",
        "model.load_state_dict(torch.load('sentiment/Model/myModelsmall8.pt'))\n",
        "model.eval()\n",
        "model = model.to(device)\n",
        "#print Train Accuracy\n",
        "batch_X, batch_y = train_input[0:batch_size], train_output[0:batch_size]\n",
        "batch_X = batch_X.to(device)\n",
        "batch_y = batch_y.to(device)\n",
        "output, hidden = model(batch_X, batch_size = batch_size)\n",
        "printLoss, printAccuracy = evaluate(model, train_input, train_output, criterion, batch_size)\n",
        "print(printLoss, printAccuracy)\n",
        "\n",
        "#print Validation Accuracy\n",
        "batch_size = 2000\n",
        "batch_X, batch_y = val_input[0:batch_size], val_output[0:batch_size]\n",
        "batch_X = batch_X.to(device)\n",
        "batch_y = batch_y.to(device)\n",
        "output, hidden = model(batch_X, batch_size = batch_size)\n",
        "printLoss, printAccuracy = evaluate(model, val_input, val_output, criterion, batch_size)\n",
        "print(printLoss, printAccuracy)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available\n",
            "0.08412731438875198 97.7\n",
            "0.098625548183918 97.05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckFcORv0trOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Get parameters of the loaded model\n",
        "ordir = model.state_dict()\n",
        "B = ordir['rnn.weight_ih_l0'].cpu()\n",
        "B_bias = ordir['rnn.bias_ih_l0'].cpu()\n",
        "A = ordir['rnn.weight_hh_l0'].cpu()\n",
        "A_bias = ordir['rnn.bias_hh_l0'].cpu()\n",
        "C = ordir['fc.weight'].cpu()\n",
        "C_bias = ordir['fc.bias'].cpu()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6krWSt6uAXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##############################Product of parameter and input word vector\n",
        "for i in range(100):\n",
        "    inputword = embeddings(torch.tensor(i, dtype=torch.long))\n",
        "    print(torch.norm(torch.mm(B,inputword.view(10,1))))#default frob. norm\n",
        "#     print(torch.sum(torch.mm(InputParam,inputword.view(10,1))+InputBias.view(8,1)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}