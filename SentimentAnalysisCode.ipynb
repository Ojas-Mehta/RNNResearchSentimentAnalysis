{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysisCode.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ojas-Mehta/RNNResearchSentimentAnalysis/blob/master/SentimentAnalysisCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSqiB0jwQcgr",
        "colab_type": "code",
        "outputId": "637ab6bf-63e8-4896-accc-fafd2f5a1be3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po1TptY8WhBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pickle\n",
        "import json\n",
        "import pandas as pd\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlYVmegeWcGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip3 install git+https://github.com/PetrochukM/PyTorch-NLP.git\n",
        "# from torchnlp.word_to_vector import GloVe\n",
        "# vectors = GloVe(name  = 'twitter.27B',dim=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27FFatoKqbCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pickle.dump(a, open(f'/content/drive/My Drive/sentiment/pretrained.pkl', 'wb'))\n",
        "# words = pickle.load(open(f'/content/drive/My Drive/sentiment/pretrained.pkl', 'rb'))\n",
        "# print(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUTzBcALhpn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# #Generate synthetic data\n",
        "# #train_synth.csv, test_synth.csv\n",
        "# import numpy as np\n",
        "# import csv\n",
        "# dataset = []\n",
        "# dataset_size = 2000\n",
        "# for i in range(dataset_size):\n",
        "#     a = np.floor(100*np.random.rand(10)).astype(int)\n",
        "#     if(((80 <= a) & (a < 89)).sum()>=((90 <= a) & (a < 100)).sum()):\n",
        "#       label = 1\n",
        "#     else:\n",
        "#       label = 0\n",
        "#     dataset.append([a.tolist(),label])\n",
        "# with open('/content/drive/My Drive/sentiment/data/val_small.csv', 'w') as csvFile:\n",
        "#     writer = csv.writer(csvFile)\n",
        "#     writer.writerows(dataset)\n",
        "# csvFile.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBJ39LSkBZ6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read data\n",
        "import pandas as pd\n",
        "train_data = pd.read_csv('/content/drive/My Drive/sentiment/data/train_small.csv', header = None)\n",
        "val_data = pd.read_csv('/content/drive/My Drive/sentiment/data/val_small.csv', header = None)\n",
        "\n",
        "test_data = pd.read_csv('/content/drive/My Drive/sentiment/data/test_small.csv', header = None)\n",
        "train_X_list = train_data[0].tolist()\n",
        "train_y = train_data[1].tolist()\n",
        "val_X_list = val_data[0].tolist()\n",
        "val_y = val_data[1].tolist()\n",
        "test_X_list = test_data[0].tolist()\n",
        "test_y = test_data[1].tolist()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRFfV-AUybLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preprocesssing: Numeric from string\n",
        "torch.manual_seed(2109)\n",
        "def stringToList(string):\n",
        "    string = string[1:len(string)-1]\n",
        "    try:\n",
        "        if len(string) != 0: \n",
        "            tempList = string.split(\", \")\n",
        "            newList = list(map(lambda x: int(x), tempList))\n",
        "        else:\n",
        "            newList = []\n",
        "    except:\n",
        "        newList = [-9999]\n",
        "    return(newList)\n",
        "train_X_list = [stringToList(x) for x in train_X_list]\n",
        "train_X = torch.tensor(train_X_list, dtype=torch.long)\n",
        "val_X_list = [stringToList(x) for x in val_X_list]\n",
        "val_X = torch.tensor(val_X_list, dtype=torch.long)\n",
        "test_X_list = [stringToList(x) for x in test_X_list]\n",
        "test_X = torch.tensor(test_X_list, dtype=torch.long)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwDBRlnx51-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define hyperparameters\n",
        "input_dim = 10\n",
        "output_dim = 2\n",
        "n_epochs = 150\n",
        "batch_size = 100\n",
        "lr = 0.001\n",
        "hidden_dimension = 8\n",
        "patience_param = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXizYy5pjKxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(2109)\n",
        "#Get embeddings\n",
        "embeddings = nn.Embedding(100, input_dim)\n",
        "train_input = embeddings(train_X)\n",
        "train_output = torch.tensor(train_y, dtype=torch.long)\n",
        "\n",
        "val_input = embeddings(val_X)\n",
        "val_output = torch.tensor(val_y, dtype=torch.long)\n",
        "test_input = embeddings(test_X)\n",
        "result = []\n",
        "# pickle.dump({'train':train_input, 'trainy':train_y, 'validation':val_input, 'valy':val_y, 'test':test_input},open(f'/content/drive/My Drive/sentiment/Results/InputEmbeddings.pkl', 'wb'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWDKHN68HjXa",
        "colab_type": "code",
        "outputId": "cb4ad486-c822-4661-8a88-fbfccd57e109",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "torch.manual_seed(2109)\n",
        "#Code used for TRAINING\n",
        "def repackage_hidden(h):\n",
        "    \"\"\"Wraps hidden states in new Variables, to detach them from their history.\"\"\"\n",
        "    if type(h) == Variable:\n",
        "        return Variable(h.data)\n",
        "    else:\n",
        "        return tuple(repackage_hidden(v) for v in h)\n",
        "\n",
        "def evaluate(tempmodel, dataX, dataY, criterion):\n",
        "  \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    correct_pred = 0\n",
        "    tempmodel.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, dataX.shape[0], batch_size):\n",
        "            batchX, batchy = dataX[i:i+batch_size], dataY[i:i+batch_size]\n",
        "            batchX = batchX.to(device)\n",
        "            batchy = batchy.to(device)\n",
        "            output, hidden = tempmodel(batchX)          \n",
        "            loss = criterion(hidden, batchy)\n",
        "\n",
        "            epoch_loss += loss.item()*batch_size\n",
        "            _, predicted_labels = torch.max(hidden, 1)\n",
        "            correct_pred += (predicted_labels==batchy).sum().item()\n",
        "        accuracy = correct_pred/ len(dataX)*100\n",
        "        epoch_loss /= len(dataX)   \n",
        "    return epoch_loss, accuracy\n",
        "\n",
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")\n",
        "    \n",
        "    \n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        # Defining some parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        #Defining the layers\n",
        "        # RNN Layer\n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # Initializing hidden state for first input using method defined below\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        # Passing in the input and hidden state into the model and obtaining outputs\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
        "        #out = out.contiguous().view(-1, self.hidden_dim)\n",
        "#         print(out.shape)\n",
        "#         print(hidden.shape)\n",
        "\n",
        "        hidden = hidden.transpose(0,1).contiguous().view(batch_size, -1)\n",
        "        hidden = self.fc(hidden)\n",
        "#         print(out.shape, hidden.shape)\n",
        "        return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
        "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
        "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
        "        hidden = hidden.to(device)\n",
        "        return hidden\n",
        "      \n",
        "# Instantiate the model with hyperparameters\n",
        "model = Model(input_size=input_dim, output_size=output_dim, hidden_dim=hidden_dimension, n_layers=1)\n",
        "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "# Define Loss, Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "printLoss, printAccuracy = evaluate(model, train_input, train_output, criterion)\n",
        "print(\"Training Loss and Accuracy: {:.4f}, {:.4f}\".format(printLoss, printAccuracy))\n",
        "printLoss, printAccuracy = evaluate(model, val_input, val_output, criterion)\n",
        "print(\"Validation Loss and Accuracy: {:.4f}, {:.4f}\".format(printLoss, printAccuracy))\n",
        "oldAcc = printAccuracy\n",
        "k = 0\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    model.train()\n",
        "    for i in range(0, train_input.shape[0], batch_size):\n",
        "        optimizer.zero_grad()\n",
        "        batch_X, batch_y = train_input[i:i+batch_size], train_output[i:i+batch_size]\n",
        "        batch_X = batch_X.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "        output, hidden = model(batch_X)\n",
        "        loss = criterion(hidden, batch_y)\n",
        "        loss.backward(retain_graph=True) # Does backpropagation and calculates gradients\n",
        "        optimizer.step() # Updates the weights accordingly\n",
        "    \n",
        "    if 1:\n",
        "        \n",
        "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
        "        printLoss, printAccuracy = evaluate(model, train_input, train_output, criterion)\n",
        "        print(\"Training Loss and Accuracy: {:.4f}, {:.4f}\".format(printLoss, printAccuracy))\n",
        "        printLoss, printAccuracy = evaluate(model, val_input, val_output, criterion)\n",
        "        print(\"Validation Loss and Accuracy: {:.4f}, {:.4f}\".format(printLoss, printAccuracy))\n",
        "        if(oldAcc>printAccuracy):\n",
        "          lr/=2\n",
        "          k+=1\n",
        "        else:\n",
        "          k=0\n",
        "        if(k>=patience_param):\n",
        "          break\n",
        "        oldAcc = printAccuracy\n",
        "result = []\n",
        "with open('/content/drive/My Drive/sentiment/Results/Result8ss.json', 'w') as f:\n",
        "  result.append({epoch: str(model.state_dict())})\n",
        "  json.dump(result, f)\n",
        "# torch.save(model.state_dict(), '/content/drive/My Drive/sentiment/Model/myModelsmall.pth')\n",
        "torch.save(model.state_dict(), '/content/drive/My Drive/sentiment/Model/myModelsmall8ss.pt')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available\n",
            "Training Loss and Accuracy: 0.7566, 40.2667\n",
            "Validation Loss and Accuracy: 0.7626, 38.8500\n",
            "Epoch: 1/150............. Training Loss and Accuracy: 0.6551, 62.8667\n",
            "Validation Loss and Accuracy: 0.6512, 63.9500\n",
            "Epoch: 2/150............. Training Loss and Accuracy: 0.6434, 63.1000\n",
            "Validation Loss and Accuracy: 0.6379, 64.9000\n",
            "Epoch: 3/150............. Training Loss and Accuracy: 0.6260, 65.1600\n",
            "Validation Loss and Accuracy: 0.6188, 65.9500\n",
            "Epoch: 4/150............. Training Loss and Accuracy: 0.6163, 65.8800\n",
            "Validation Loss and Accuracy: 0.6085, 66.3000\n",
            "Epoch: 5/150............. Training Loss and Accuracy: 0.6071, 66.6133\n",
            "Validation Loss and Accuracy: 0.5988, 66.8500\n",
            "Epoch: 6/150............. Training Loss and Accuracy: 0.5926, 67.7467\n",
            "Validation Loss and Accuracy: 0.5840, 67.7500\n",
            "Epoch: 7/150............. Training Loss and Accuracy: 0.5700, 69.3800\n",
            "Validation Loss and Accuracy: 0.5620, 70.5000\n",
            "Epoch: 8/150............. Training Loss and Accuracy: 0.5293, 72.8800\n",
            "Validation Loss and Accuracy: 0.5237, 73.1000\n",
            "Epoch: 9/150............. Training Loss and Accuracy: 0.4917, 75.6267\n",
            "Validation Loss and Accuracy: 0.4894, 76.3000\n",
            "Epoch: 10/150............. Training Loss and Accuracy: 0.4646, 77.5733\n",
            "Validation Loss and Accuracy: 0.4638, 77.8000\n",
            "Epoch: 11/150............. Training Loss and Accuracy: 0.4424, 78.9467\n",
            "Validation Loss and Accuracy: 0.4424, 79.1500\n",
            "Epoch: 12/150............. Training Loss and Accuracy: 0.4229, 80.2333\n",
            "Validation Loss and Accuracy: 0.4230, 80.0500\n",
            "Epoch: 13/150............. Training Loss and Accuracy: 0.4058, 81.4133\n",
            "Validation Loss and Accuracy: 0.4056, 81.0500\n",
            "Epoch: 14/150............. Training Loss and Accuracy: 0.3907, 82.4200\n",
            "Validation Loss and Accuracy: 0.3900, 81.7000\n",
            "Epoch: 15/150............. Training Loss and Accuracy: 0.3775, 83.1600\n",
            "Validation Loss and Accuracy: 0.3762, 82.9500\n",
            "Epoch: 16/150............. Training Loss and Accuracy: 0.3657, 83.9933\n",
            "Validation Loss and Accuracy: 0.3640, 84.0000\n",
            "Epoch: 17/150............. Training Loss and Accuracy: 0.3553, 84.5800\n",
            "Validation Loss and Accuracy: 0.3532, 85.2500\n",
            "Epoch: 18/150............. Training Loss and Accuracy: 0.3459, 85.1133\n",
            "Validation Loss and Accuracy: 0.3437, 85.5500\n",
            "Epoch: 19/150............. Training Loss and Accuracy: 0.3374, 85.5267\n",
            "Validation Loss and Accuracy: 0.3352, 85.9000\n",
            "Epoch: 20/150............. Training Loss and Accuracy: 0.3296, 86.1067\n",
            "Validation Loss and Accuracy: 0.3275, 86.0500\n",
            "Epoch: 21/150............. Training Loss and Accuracy: 0.3223, 86.5400\n",
            "Validation Loss and Accuracy: 0.3205, 86.5500\n",
            "Epoch: 22/150............. Training Loss and Accuracy: 0.3154, 86.8533\n",
            "Validation Loss and Accuracy: 0.3140, 86.9500\n",
            "Epoch: 23/150............. Training Loss and Accuracy: 0.3090, 87.1667\n",
            "Validation Loss and Accuracy: 0.3079, 87.1000\n",
            "Epoch: 24/150............. Training Loss and Accuracy: 0.3029, 87.4533\n",
            "Validation Loss and Accuracy: 0.3023, 87.5000\n",
            "Epoch: 25/150............. Training Loss and Accuracy: 0.2971, 87.8133\n",
            "Validation Loss and Accuracy: 0.2971, 87.7000\n",
            "Epoch: 26/150............. Training Loss and Accuracy: 0.2918, 88.0400\n",
            "Validation Loss and Accuracy: 0.2923, 87.9500\n",
            "Epoch: 27/150............. Training Loss and Accuracy: 0.2868, 88.3267\n",
            "Validation Loss and Accuracy: 0.2878, 88.2500\n",
            "Epoch: 28/150............. Training Loss and Accuracy: 0.2821, 88.4600\n",
            "Validation Loss and Accuracy: 0.2836, 88.5500\n",
            "Epoch: 29/150............. Training Loss and Accuracy: 0.2777, 88.6800\n",
            "Validation Loss and Accuracy: 0.2797, 88.7500\n",
            "Epoch: 30/150............. Training Loss and Accuracy: 0.2735, 88.8867\n",
            "Validation Loss and Accuracy: 0.2759, 88.7000\n",
            "Epoch: 31/150............. Training Loss and Accuracy: 0.2694, 89.1000\n",
            "Validation Loss and Accuracy: 0.2723, 88.9000\n",
            "Epoch: 32/150............. Training Loss and Accuracy: 0.2655, 89.2600\n",
            "Validation Loss and Accuracy: 0.2688, 89.1000\n",
            "Epoch: 33/150............. Training Loss and Accuracy: 0.2616, 89.5467\n",
            "Validation Loss and Accuracy: 0.2654, 89.1500\n",
            "Epoch: 34/150............. Training Loss and Accuracy: 0.2577, 89.7800\n",
            "Validation Loss and Accuracy: 0.2621, 89.5500\n",
            "Epoch: 35/150............. Training Loss and Accuracy: 0.2539, 90.0000\n",
            "Validation Loss and Accuracy: 0.2587, 89.9000\n",
            "Epoch: 36/150............. Training Loss and Accuracy: 0.2501, 90.0933\n",
            "Validation Loss and Accuracy: 0.2554, 90.3500\n",
            "Epoch: 37/150............. Training Loss and Accuracy: 0.2463, 90.2867\n",
            "Validation Loss and Accuracy: 0.2520, 90.5000\n",
            "Epoch: 38/150............. Training Loss and Accuracy: 0.2424, 90.4933\n",
            "Validation Loss and Accuracy: 0.2486, 90.5000\n",
            "Epoch: 39/150............. Training Loss and Accuracy: 0.2386, 90.6800\n",
            "Validation Loss and Accuracy: 0.2452, 90.6000\n",
            "Epoch: 40/150............. Training Loss and Accuracy: 0.2347, 90.8667\n",
            "Validation Loss and Accuracy: 0.2417, 90.9000\n",
            "Epoch: 41/150............. Training Loss and Accuracy: 0.2309, 91.0667\n",
            "Validation Loss and Accuracy: 0.2382, 90.8500\n",
            "Epoch: 42/150............. Training Loss and Accuracy: 0.2270, 91.4067\n",
            "Validation Loss and Accuracy: 0.2346, 91.0000\n",
            "Epoch: 43/150............. Training Loss and Accuracy: 0.2231, 91.6600\n",
            "Validation Loss and Accuracy: 0.2310, 91.2000\n",
            "Epoch: 44/150............. Training Loss and Accuracy: 0.2193, 91.8467\n",
            "Validation Loss and Accuracy: 0.2274, 91.4500\n",
            "Epoch: 45/150............. Training Loss and Accuracy: 0.2156, 91.9600\n",
            "Validation Loss and Accuracy: 0.2239, 91.6000\n",
            "Epoch: 46/150............. Training Loss and Accuracy: 0.2120, 92.2000\n",
            "Validation Loss and Accuracy: 0.2203, 91.7500\n",
            "Epoch: 47/150............. Training Loss and Accuracy: 0.2085, 92.3133\n",
            "Validation Loss and Accuracy: 0.2169, 91.9000\n",
            "Epoch: 48/150............. Training Loss and Accuracy: 0.2052, 92.4533\n",
            "Validation Loss and Accuracy: 0.2136, 92.1000\n",
            "Epoch: 49/150............. Training Loss and Accuracy: 0.2020, 92.6733\n",
            "Validation Loss and Accuracy: 0.2103, 92.4000\n",
            "Epoch: 50/150............. Training Loss and Accuracy: 0.1990, 92.8267\n",
            "Validation Loss and Accuracy: 0.2072, 92.6000\n",
            "Epoch: 51/150............. Training Loss and Accuracy: 0.1961, 92.9267\n",
            "Validation Loss and Accuracy: 0.2042, 92.8000\n",
            "Epoch: 52/150............. Training Loss and Accuracy: 0.1933, 93.0400\n",
            "Validation Loss and Accuracy: 0.2012, 92.9500\n",
            "Epoch: 53/150............. Training Loss and Accuracy: 0.1907, 93.2067\n",
            "Validation Loss and Accuracy: 0.1984, 93.4000\n",
            "Epoch: 54/150............. Training Loss and Accuracy: 0.1882, 93.3000\n",
            "Validation Loss and Accuracy: 0.1957, 93.4000\n",
            "Epoch: 55/150............. Training Loss and Accuracy: 0.1858, 93.4200\n",
            "Validation Loss and Accuracy: 0.1931, 93.5500\n",
            "Epoch: 56/150............. Training Loss and Accuracy: 0.1835, 93.5067\n",
            "Validation Loss and Accuracy: 0.1907, 93.5500\n",
            "Epoch: 57/150............. Training Loss and Accuracy: 0.1813, 93.6000\n",
            "Validation Loss and Accuracy: 0.1883, 93.5000\n",
            "Epoch: 58/150............. Training Loss and Accuracy: 0.1792, 93.6400\n",
            "Validation Loss and Accuracy: 0.1861, 93.5000\n",
            "Epoch: 59/150............. Training Loss and Accuracy: 0.1772, 93.7400\n",
            "Validation Loss and Accuracy: 0.1839, 93.7000\n",
            "Epoch: 60/150............. Training Loss and Accuracy: 0.1753, 93.8333\n",
            "Validation Loss and Accuracy: 0.1819, 93.7000\n",
            "Epoch: 61/150............. Training Loss and Accuracy: 0.1734, 93.9733\n",
            "Validation Loss and Accuracy: 0.1800, 93.6500\n",
            "Epoch: 62/150............. Training Loss and Accuracy: 0.1717, 94.0467\n",
            "Validation Loss and Accuracy: 0.1781, 93.8000\n",
            "Epoch: 63/150............. Training Loss and Accuracy: 0.1700, 94.1800\n",
            "Validation Loss and Accuracy: 0.1764, 93.9500\n",
            "Epoch: 64/150............. Training Loss and Accuracy: 0.1683, 94.3200\n",
            "Validation Loss and Accuracy: 0.1747, 94.1000\n",
            "Epoch: 65/150............. Training Loss and Accuracy: 0.1667, 94.4067\n",
            "Validation Loss and Accuracy: 0.1730, 94.1500\n",
            "Epoch: 66/150............. Training Loss and Accuracy: 0.1651, 94.4667\n",
            "Validation Loss and Accuracy: 0.1714, 94.2000\n",
            "Epoch: 67/150............. Training Loss and Accuracy: 0.1636, 94.5267\n",
            "Validation Loss and Accuracy: 0.1699, 94.2500\n",
            "Epoch: 68/150............. Training Loss and Accuracy: 0.1621, 94.6067\n",
            "Validation Loss and Accuracy: 0.1684, 94.2500\n",
            "Epoch: 69/150............. Training Loss and Accuracy: 0.1606, 94.7333\n",
            "Validation Loss and Accuracy: 0.1670, 94.3500\n",
            "Epoch: 70/150............. Training Loss and Accuracy: 0.1591, 94.8333\n",
            "Validation Loss and Accuracy: 0.1656, 94.4500\n",
            "Epoch: 71/150............. Training Loss and Accuracy: 0.1577, 94.9000\n",
            "Validation Loss and Accuracy: 0.1642, 94.4000\n",
            "Epoch: 72/150............. Training Loss and Accuracy: 0.1563, 94.9467\n",
            "Validation Loss and Accuracy: 0.1628, 94.4500\n",
            "Epoch: 73/150............. Training Loss and Accuracy: 0.1549, 95.0467\n",
            "Validation Loss and Accuracy: 0.1615, 94.4500\n",
            "Epoch: 74/150............. Training Loss and Accuracy: 0.1535, 95.0667\n",
            "Validation Loss and Accuracy: 0.1602, 94.5500\n",
            "Epoch: 75/150............. Training Loss and Accuracy: 0.1521, 95.1000\n",
            "Validation Loss and Accuracy: 0.1589, 94.7000\n",
            "Epoch: 76/150............. Training Loss and Accuracy: 0.1507, 95.1733\n",
            "Validation Loss and Accuracy: 0.1577, 94.8000\n",
            "Epoch: 77/150............. Training Loss and Accuracy: 0.1494, 95.2000\n",
            "Validation Loss and Accuracy: 0.1564, 94.8500\n",
            "Epoch: 78/150............. Training Loss and Accuracy: 0.1480, 95.2667\n",
            "Validation Loss and Accuracy: 0.1552, 95.1000\n",
            "Epoch: 79/150............. Training Loss and Accuracy: 0.1466, 95.3267\n",
            "Validation Loss and Accuracy: 0.1540, 95.1500\n",
            "Epoch: 80/150............. Training Loss and Accuracy: 0.1453, 95.4000\n",
            "Validation Loss and Accuracy: 0.1528, 95.1500\n",
            "Epoch: 81/150............. Training Loss and Accuracy: 0.1439, 95.5000\n",
            "Validation Loss and Accuracy: 0.1516, 95.2000\n",
            "Epoch: 82/150............. Training Loss and Accuracy: 0.1425, 95.5933\n",
            "Validation Loss and Accuracy: 0.1504, 95.2500\n",
            "Epoch: 83/150............. Training Loss and Accuracy: 0.1412, 95.6200\n",
            "Validation Loss and Accuracy: 0.1492, 95.2500\n",
            "Epoch: 84/150............. Training Loss and Accuracy: 0.1398, 95.7333\n",
            "Validation Loss and Accuracy: 0.1480, 95.2500\n",
            "Epoch: 85/150............. Training Loss and Accuracy: 0.1385, 95.7933\n",
            "Validation Loss and Accuracy: 0.1469, 95.3500\n",
            "Epoch: 86/150............. Training Loss and Accuracy: 0.1371, 95.8600\n",
            "Validation Loss and Accuracy: 0.1457, 95.3500\n",
            "Epoch: 87/150............. Training Loss and Accuracy: 0.1358, 95.9267\n",
            "Validation Loss and Accuracy: 0.1446, 95.3500\n",
            "Epoch: 88/150............. Training Loss and Accuracy: 0.1344, 95.9867\n",
            "Validation Loss and Accuracy: 0.1435, 95.3500\n",
            "Epoch: 89/150............. Training Loss and Accuracy: 0.1331, 96.1067\n",
            "Validation Loss and Accuracy: 0.1423, 95.4500\n",
            "Epoch: 90/150............. Training Loss and Accuracy: 0.1318, 96.2000\n",
            "Validation Loss and Accuracy: 0.1412, 95.5500\n",
            "Epoch: 91/150............. Training Loss and Accuracy: 0.1305, 96.2600\n",
            "Validation Loss and Accuracy: 0.1401, 95.6000\n",
            "Epoch: 92/150............. Training Loss and Accuracy: 0.1292, 96.3200\n",
            "Validation Loss and Accuracy: 0.1390, 95.6000\n",
            "Epoch: 93/150............. Training Loss and Accuracy: 0.1279, 96.3533\n",
            "Validation Loss and Accuracy: 0.1380, 95.7500\n",
            "Epoch: 94/150............. Training Loss and Accuracy: 0.1267, 96.3933\n",
            "Validation Loss and Accuracy: 0.1369, 95.8000\n",
            "Epoch: 95/150............. Training Loss and Accuracy: 0.1255, 96.4867\n",
            "Validation Loss and Accuracy: 0.1359, 95.8500\n",
            "Epoch: 96/150............. Training Loss and Accuracy: 0.1243, 96.5133\n",
            "Validation Loss and Accuracy: 0.1349, 95.8500\n",
            "Epoch: 97/150............. Training Loss and Accuracy: 0.1231, 96.6133\n",
            "Validation Loss and Accuracy: 0.1339, 95.8000\n",
            "Epoch: 98/150............. Training Loss and Accuracy: 0.1220, 96.6333\n",
            "Validation Loss and Accuracy: 0.1329, 95.9000\n",
            "Epoch: 99/150............. Training Loss and Accuracy: 0.1209, 96.6200\n",
            "Validation Loss and Accuracy: 0.1320, 95.8500\n",
            "Epoch: 100/150............. Training Loss and Accuracy: 0.1198, 96.6400\n",
            "Validation Loss and Accuracy: 0.1311, 95.8000\n",
            "Epoch: 101/150............. Training Loss and Accuracy: 0.1187, 96.6600\n",
            "Validation Loss and Accuracy: 0.1301, 95.8500\n",
            "Epoch: 102/150............. Training Loss and Accuracy: 0.1177, 96.6867\n",
            "Validation Loss and Accuracy: 0.1293, 96.1000\n",
            "Epoch: 103/150............. Training Loss and Accuracy: 0.1167, 96.7400\n",
            "Validation Loss and Accuracy: 0.1284, 96.1500\n",
            "Epoch: 104/150............. Training Loss and Accuracy: 0.1158, 96.7800\n",
            "Validation Loss and Accuracy: 0.1276, 96.1000\n",
            "Epoch: 105/150............. Training Loss and Accuracy: 0.1148, 96.8200\n",
            "Validation Loss and Accuracy: 0.1267, 96.1000\n",
            "Epoch: 106/150............. Training Loss and Accuracy: 0.1139, 96.8467\n",
            "Validation Loss and Accuracy: 0.1259, 96.2000\n",
            "Epoch: 107/150............. Training Loss and Accuracy: 0.1130, 96.8667\n",
            "Validation Loss and Accuracy: 0.1251, 96.2000\n",
            "Epoch: 108/150............. Training Loss and Accuracy: 0.1121, 96.8933\n",
            "Validation Loss and Accuracy: 0.1244, 96.2000\n",
            "Epoch: 109/150............. Training Loss and Accuracy: 0.1113, 96.9200\n",
            "Validation Loss and Accuracy: 0.1236, 96.1500\n",
            "Epoch: 110/150............. Training Loss and Accuracy: 0.1104, 96.9333\n",
            "Validation Loss and Accuracy: 0.1229, 96.1500\n",
            "Epoch: 111/150............. Training Loss and Accuracy: 0.1096, 96.9600\n",
            "Validation Loss and Accuracy: 0.1222, 96.2000\n",
            "Epoch: 112/150............. Training Loss and Accuracy: 0.1088, 96.9800\n",
            "Validation Loss and Accuracy: 0.1214, 96.1500\n",
            "Epoch: 113/150............. Training Loss and Accuracy: 0.1080, 97.0400\n",
            "Validation Loss and Accuracy: 0.1207, 96.1000\n",
            "Epoch: 114/150............. Training Loss and Accuracy: 0.1072, 97.0400\n",
            "Validation Loss and Accuracy: 0.1200, 96.3000\n",
            "Epoch: 115/150............. Training Loss and Accuracy: 0.1065, 97.0667\n",
            "Validation Loss and Accuracy: 0.1194, 96.3500\n",
            "Epoch: 116/150............. Training Loss and Accuracy: 0.1057, 97.1000\n",
            "Validation Loss and Accuracy: 0.1187, 96.3500\n",
            "Epoch: 117/150............. Training Loss and Accuracy: 0.1050, 97.1267\n",
            "Validation Loss and Accuracy: 0.1180, 96.3000\n",
            "Epoch: 118/150............. Training Loss and Accuracy: 0.1042, 97.1533\n",
            "Validation Loss and Accuracy: 0.1174, 96.3500\n",
            "Epoch: 119/150............. Training Loss and Accuracy: 0.1035, 97.1867\n",
            "Validation Loss and Accuracy: 0.1168, 96.3000\n",
            "Epoch: 120/150............. Training Loss and Accuracy: 0.1028, 97.1800\n",
            "Validation Loss and Accuracy: 0.1161, 96.3500\n",
            "Epoch: 121/150............. Training Loss and Accuracy: 0.1021, 97.2133\n",
            "Validation Loss and Accuracy: 0.1155, 96.5000\n",
            "Epoch: 122/150............. Training Loss and Accuracy: 0.1014, 97.2200\n",
            "Validation Loss and Accuracy: 0.1149, 96.5000\n",
            "Epoch: 123/150............. Training Loss and Accuracy: 0.1007, 97.2267\n",
            "Validation Loss and Accuracy: 0.1143, 96.4500\n",
            "Epoch: 124/150............. Training Loss and Accuracy: 0.1000, 97.2533\n",
            "Validation Loss and Accuracy: 0.1137, 96.4000\n",
            "Epoch: 125/150............. Training Loss and Accuracy: 0.0994, 97.2800\n",
            "Validation Loss and Accuracy: 0.1131, 96.4500\n",
            "Epoch: 126/150............. Training Loss and Accuracy: 0.0987, 97.3067\n",
            "Validation Loss and Accuracy: 0.1125, 96.4500\n",
            "Epoch: 127/150............. Training Loss and Accuracy: 0.0981, 97.3400\n",
            "Validation Loss and Accuracy: 0.1119, 96.4500\n",
            "Epoch: 128/150............. Training Loss and Accuracy: 0.0974, 97.3200\n",
            "Validation Loss and Accuracy: 0.1113, 96.4500\n",
            "Epoch: 129/150............. Training Loss and Accuracy: 0.0968, 97.3333\n",
            "Validation Loss and Accuracy: 0.1107, 96.4500\n",
            "Epoch: 130/150............. Training Loss and Accuracy: 0.0961, 97.3467\n",
            "Validation Loss and Accuracy: 0.1101, 96.4500\n",
            "Epoch: 131/150............. Training Loss and Accuracy: 0.0955, 97.3467\n",
            "Validation Loss and Accuracy: 0.1096, 96.4500\n",
            "Epoch: 132/150............. Training Loss and Accuracy: 0.0949, 97.3867\n",
            "Validation Loss and Accuracy: 0.1090, 96.6000\n",
            "Epoch: 133/150............. Training Loss and Accuracy: 0.0942, 97.4000\n",
            "Validation Loss and Accuracy: 0.1084, 96.6000\n",
            "Epoch: 134/150............. Training Loss and Accuracy: 0.0936, 97.4133\n",
            "Validation Loss and Accuracy: 0.1079, 96.6000\n",
            "Epoch: 135/150............. Training Loss and Accuracy: 0.0930, 97.4333\n",
            "Validation Loss and Accuracy: 0.1073, 96.6500\n",
            "Epoch: 136/150............. Training Loss and Accuracy: 0.0924, 97.4333\n",
            "Validation Loss and Accuracy: 0.1067, 96.6000\n",
            "Epoch: 137/150............. Training Loss and Accuracy: 0.0918, 97.4600\n",
            "Validation Loss and Accuracy: 0.1061, 96.7000\n",
            "Epoch: 138/150............. Training Loss and Accuracy: 0.0912, 97.4867\n",
            "Validation Loss and Accuracy: 0.1056, 96.7000\n",
            "Epoch: 139/150............. Training Loss and Accuracy: 0.0906, 97.5200\n",
            "Validation Loss and Accuracy: 0.1050, 96.7000\n",
            "Epoch: 140/150............. Training Loss and Accuracy: 0.0900, 97.5533\n",
            "Validation Loss and Accuracy: 0.1044, 96.7000\n",
            "Epoch: 141/150............. Training Loss and Accuracy: 0.0894, 97.5667\n",
            "Validation Loss and Accuracy: 0.1039, 96.7000\n",
            "Epoch: 142/150............. Training Loss and Accuracy: 0.0888, 97.5667\n",
            "Validation Loss and Accuracy: 0.1033, 96.7500\n",
            "Epoch: 143/150............. Training Loss and Accuracy: 0.0882, 97.5467\n",
            "Validation Loss and Accuracy: 0.1027, 96.7500\n",
            "Epoch: 144/150............. Training Loss and Accuracy: 0.0876, 97.5667\n",
            "Validation Loss and Accuracy: 0.1021, 96.9500\n",
            "Epoch: 145/150............. Training Loss and Accuracy: 0.0871, 97.5667\n",
            "Validation Loss and Accuracy: 0.1015, 97.0000\n",
            "Epoch: 146/150............. Training Loss and Accuracy: 0.0865, 97.5867\n",
            "Validation Loss and Accuracy: 0.1010, 97.0000\n",
            "Epoch: 147/150............. Training Loss and Accuracy: 0.0859, 97.5933\n",
            "Validation Loss and Accuracy: 0.1004, 97.0500\n",
            "Epoch: 148/150............. Training Loss and Accuracy: 0.0853, 97.6067\n",
            "Validation Loss and Accuracy: 0.0998, 96.9500\n",
            "Epoch: 149/150............. Training Loss and Accuracy: 0.0847, 97.6333\n",
            "Validation Loss and Accuracy: 0.0992, 96.9500\n",
            "Epoch: 150/150............. Training Loss and Accuracy: 0.0841, 97.7000\n",
            "Validation Loss and Accuracy: 0.0986, 97.0500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-LmbDMhdZ0z",
        "colab_type": "code",
        "outputId": "52c2a739-3029-4234-a9a8-8171665ece76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#########Inference\n",
        "input_dim = 10\n",
        "output_dim = 2\n",
        "n_epochs = 50\n",
        "batch_size = 100\n",
        "lr=0.001\n",
        "\n",
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")\n",
        "    \n",
        "    \n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        # Defining some parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        #Defining the layers\n",
        "        # RNN Layer\n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # Initializing hidden state for first input using method defined below\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        # Passing in the input and hidden state into the model and obtaining outputs\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
        "        #out = out.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "        hidden = hidden.transpose(0,1).contiguous().view(batch_size, -1)\n",
        "        hidden = self.fc(hidden)\n",
        "        return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
        "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
        "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
        "        hidden = hidden.to(device)\n",
        "        return hidden\n",
        "\n",
        "# Instantiate the model with hyperparameters\n",
        "model = Model(input_size=input_dim, output_size=output_dim, hidden_dim=10, n_layers=1)\n",
        "model.load_state_dict(torch.load('/content/drive/My Drive/sentiment/Model/myModelsmall10.pt'))\n",
        "# model.eval()\n",
        "# model = model.to(device)\n",
        "# batch_X, batch_y = train_input[0:1], train_output[0:1]\n",
        "# batch_X = batch_X.to(device)\n",
        "# batch_y = batch_y.to(device)\n",
        "# output, hidden = model(batch_X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ1FU-81Hlxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "result = []\n",
        "with open('/content/drive/My Drive/sentiment/Results/SecondResultSmall.json', 'w') as f:\n",
        "          json.dump(result, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB5pL2UMQ8wQ",
        "colab_type": "code",
        "outputId": "c618229c-096f-4323-b366-865b81b8e396",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#save the model\n",
        "# torch.save(model.state_dict(), '/content/drive/My Drive/sentiment/Model/')\n",
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")\n",
        "    \n",
        "    \n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        # Defining some parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        #Defining the layers\n",
        "        # RNN Layer\n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # Initializing hidden state for first input using method defined below\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        # Passing in the input and hidden state into the model and obtaining outputs\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
        "        #out = out.contiguous().view(-1, self.hidden_dim)\n",
        "#         print(out.shape)\n",
        "#         print(hidden.shape)\n",
        "\n",
        "        hidden = hidden.transpose(0,1).contiguous().view(batch_size, -1)\n",
        "        hidden = self.fc(hidden)\n",
        "#         print(out.shape, hidden.shape)\n",
        "        return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
        "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
        "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
        "        hidden = hidden.to(device)\n",
        "        return hidden\n",
        "#Load the model\n",
        "\n",
        "model = Model(input_size=input_dim, output_size=output_dim, hidden_dim=hidden_dimension, n_layers=1)\n",
        "# Define Loss, Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "model.load_state_dict(torch.load('/content/drive/My Drive/sentiment/Model/myModelsmall10.pt'))\n",
        "# model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMTVK-4RQJ8x",
        "colab_type": "code",
        "outputId": "24078c73-202d-4039-a7be-ca3de3148baf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#########Read JSON File\n",
        "import json\n",
        "with open('/content/drive/My Drive/sentiment/Results/FirstResult.json', 'r') as f:\n",
        "  result = json.loads(f.read())\n",
        "print(len(result))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHRXvFK2SkRo",
        "colab_type": "code",
        "outputId": "fa4d80f1-98dd-4dd2-a468-c3984856a1e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "########Load Model\n",
        "torch.manual_seed(2109)\n",
        "#Code\n",
        "def repackage_hidden(h):\n",
        "    \"\"\"Wraps hidden states in new Variables, to detach them from their history.\"\"\"\n",
        "    if type(h) == Variable:\n",
        "        return Variable(h.data)\n",
        "    else:\n",
        "        return tuple(repackage_hidden(v) for v in h)\n",
        "\n",
        "def evaluate(tempmodel, dataX, dataY, criterion):\n",
        "  \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    correct_pred = 0\n",
        "    tempmodel.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, dataX.shape[0], batch_size):\n",
        "            batchX, batchy = dataX[i:i+batch_size], dataY[i:i+batch_size]\n",
        "            batchX = batchX.to(device)\n",
        "            batchy = batchy.to(device)\n",
        "            output, hidden = tempmodel(batchX)          \n",
        "            loss = criterion(hidden, batchy)\n",
        "\n",
        "            epoch_loss += loss.item()*batch_size\n",
        "            _, predicted_labels = torch.max(hidden, 1)\n",
        "            correct_pred += (predicted_labels==batchy).sum().item()\n",
        "        accuracy = correct_pred/ len(dataX)*100\n",
        "        epoch_loss /= len(dataX)   \n",
        "    return epoch_loss, accuracy\n",
        "\n",
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")\n",
        "    \n",
        "    \n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        # Defining some parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        #Defining the layers\n",
        "        # RNN Layer\n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # Initializing hidden state for first input using method defined below\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        # Passing in the input and hidden state into the model and obtaining outputs\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
        "        #out = out.contiguous().view(-1, self.hidden_dim)\n",
        "#         print(out.shape)\n",
        "#         print(hidden.shape)\n",
        "\n",
        "        hidden = hidden.transpose(0,1).contiguous().view(batch_size, -1)\n",
        "        hidden = self.fc(hidden)\n",
        "#         print(out.shape, hidden.shape)\n",
        "        return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
        "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
        "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
        "        hidden = hidden.to(device)\n",
        "        return hidden\n",
        "      \n",
        "# Instantiate the model with hyperparameters\n",
        "model = Model(input_size=input_dim, output_size=output_dim, hidden_dim=hidden_dimension, n_layers=1)\n",
        "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
        "model.load_state_dict(torch.load('/content/drive/My Drive/sentiment/Model/myModelsmall8.pt'))\n",
        "model.to(device)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (rnn): RNN(10, 8, batch_first=True)\n",
              "  (fc): Linear(in_features=8, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckFcORv0trOl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "3a59d9af-64d4-4966-d875-fc63bbbb8f76"
      },
      "source": [
        "###Get parameters of the loaded model\n",
        "ordir = model.state_dict()\n",
        "print(ordir)\n",
        "InputParam = ordir['rnn.weight_ih_l0'].cpu()\n",
        "InputBias = ordir['rnn.bias_ih_l0'].cpu()\n",
        "HiddenParam = ordir['rnn.weight_hh_l0'].cpu()\n",
        "HiddenBias = ordir['rnn.bias_hh_l0'].cpu()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('rnn.weight_ih_l0', tensor([[ 0.5346,  1.0179,  0.0586, -0.1215, -0.7051, -0.5493,  0.2434,  0.1060,\n",
            "         -0.4051, -0.5529],\n",
            "        [-0.3803, -0.2369,  0.7409,  0.3470, -0.1311, -0.0642,  0.1315, -0.9807,\n",
            "         -0.2692, -0.2011],\n",
            "        [-0.7092,  0.3890,  0.0813, -0.1533,  0.1883,  0.3681,  0.1788,  0.3680,\n",
            "         -0.2529,  0.1657],\n",
            "        [-0.3872,  0.1718,  0.3645,  0.3122,  0.2762,  0.5664, -0.2306,  0.6595,\n",
            "         -0.5076,  0.2364],\n",
            "        [ 0.5229,  0.6768,  0.0530, -0.2626, -0.2817,  0.2029,  0.2200, -0.3312,\n",
            "         -0.2490, -0.6428],\n",
            "        [-0.7145, -0.0238,  0.6449,  0.4349, -0.1739, -0.3180, -0.0571,  0.0758,\n",
            "          0.4326,  0.3535],\n",
            "        [ 0.1014, -0.1125, -0.0243,  0.3305,  0.1069, -0.0590, -0.0108,  0.0933,\n",
            "         -0.1592, -0.1502],\n",
            "        [-0.6407,  0.0577, -0.4438,  0.3906,  0.5159, -0.2522,  0.1429,  0.2993,\n",
            "          0.4600, -0.1553]], device='cuda:0')), ('rnn.weight_hh_l0', tensor([[ 0.1411,  0.1243, -0.1780,  0.1757, -0.1130, -0.1530, -0.3004,  0.1525],\n",
            "        [ 0.1725,  0.1536, -0.2265,  0.2203, -0.1594, -0.2087, -0.3815,  0.1838],\n",
            "        [-0.1152, -0.1027,  0.1652, -0.1648,  0.1121,  0.1439,  0.2504, -0.1189],\n",
            "        [ 0.1297,  0.1123, -0.1238,  0.1278, -0.1194, -0.1270, -0.2191,  0.1138],\n",
            "        [-0.0998, -0.0865,  0.0931, -0.0996,  0.0964,  0.1052,  0.1757, -0.0717],\n",
            "        [-0.1034, -0.0948,  0.1551, -0.1517,  0.0977,  0.1212,  0.2339, -0.1022],\n",
            "        [-0.3249, -0.2924,  0.3867, -0.3772,  0.3086,  0.3782,  0.6217, -0.3155],\n",
            "        [ 0.1435,  0.1251, -0.1756,  0.1681, -0.1300, -0.1620, -0.3034,  0.1196]],\n",
            "       device='cuda:0')), ('rnn.bias_ih_l0', tensor([ 0.0818,  0.1768, -0.4855,  0.2976,  0.4906,  0.0681,  0.1469,  0.0845],\n",
            "       device='cuda:0')), ('rnn.bias_hh_l0', tensor([ 0.2351,  0.0111,  0.0304, -0.0847,  0.4509, -0.1795,  0.0641,  0.0094],\n",
            "       device='cuda:0')), ('fc.weight', tensor([[-2.8884, -2.5867,  3.5239, -3.3690,  2.7181,  3.2612,  5.5839, -2.7132],\n",
            "        [ 2.6059,  2.5085, -3.2882,  3.3231, -2.3125, -3.2147, -5.5908,  2.7184]],\n",
            "       device='cuda:0')), ('fc.bias', tensor([ 0.8659, -0.7761], device='cuda:0'))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6krWSt6uAXn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "579c602d-f9c2-4b9a-c230-d171601c29fe"
      },
      "source": [
        "##############################Product of parameter and input word vector\n",
        "# train_input[0].to(device)\n",
        "# # InputParam[0].to(device)\n",
        "# InputParam[0]*train_input[0]\n",
        "# train_input.to(device)\n",
        "for i in range(100):\n",
        "    inputword = embeddings(torch.tensor(i, dtype=torch.long))\n",
        "    print(torch.norm(torch.mm(InputParam,inputword.view(10,1))+InputBias.view(8,1)))#default fr\n",
        "#     print(torch.sum(torch.mm(InputParam,inputword.view(10,1))+InputBias.view(8,1)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.8004, grad_fn=<NormBackward0>)\n",
            "tensor(3.7301, grad_fn=<NormBackward0>)\n",
            "tensor(3.5162, grad_fn=<NormBackward0>)\n",
            "tensor(3.6228, grad_fn=<NormBackward0>)\n",
            "tensor(3.6680, grad_fn=<NormBackward0>)\n",
            "tensor(2.3133, grad_fn=<NormBackward0>)\n",
            "tensor(3.9492, grad_fn=<NormBackward0>)\n",
            "tensor(2.2190, grad_fn=<NormBackward0>)\n",
            "tensor(3.0481, grad_fn=<NormBackward0>)\n",
            "tensor(2.0381, grad_fn=<NormBackward0>)\n",
            "tensor(2.3953, grad_fn=<NormBackward0>)\n",
            "tensor(2.5231, grad_fn=<NormBackward0>)\n",
            "tensor(2.0880, grad_fn=<NormBackward0>)\n",
            "tensor(3.8336, grad_fn=<NormBackward0>)\n",
            "tensor(5.0081, grad_fn=<NormBackward0>)\n",
            "tensor(4.0756, grad_fn=<NormBackward0>)\n",
            "tensor(3.5097, grad_fn=<NormBackward0>)\n",
            "tensor(3.3934, grad_fn=<NormBackward0>)\n",
            "tensor(3.7256, grad_fn=<NormBackward0>)\n",
            "tensor(2.6356, grad_fn=<NormBackward0>)\n",
            "tensor(3.9251, grad_fn=<NormBackward0>)\n",
            "tensor(3.3370, grad_fn=<NormBackward0>)\n",
            "tensor(4.4730, grad_fn=<NormBackward0>)\n",
            "tensor(2.2138, grad_fn=<NormBackward0>)\n",
            "tensor(3.0495, grad_fn=<NormBackward0>)\n",
            "tensor(2.4034, grad_fn=<NormBackward0>)\n",
            "tensor(2.2703, grad_fn=<NormBackward0>)\n",
            "tensor(2.5229, grad_fn=<NormBackward0>)\n",
            "tensor(2.9314, grad_fn=<NormBackward0>)\n",
            "tensor(3.6728, grad_fn=<NormBackward0>)\n",
            "tensor(2.7833, grad_fn=<NormBackward0>)\n",
            "tensor(4.3618, grad_fn=<NormBackward0>)\n",
            "tensor(3.3632, grad_fn=<NormBackward0>)\n",
            "tensor(3.3149, grad_fn=<NormBackward0>)\n",
            "tensor(2.6432, grad_fn=<NormBackward0>)\n",
            "tensor(1.6848, grad_fn=<NormBackward0>)\n",
            "tensor(2.7854, grad_fn=<NormBackward0>)\n",
            "tensor(3.5011, grad_fn=<NormBackward0>)\n",
            "tensor(2.5688, grad_fn=<NormBackward0>)\n",
            "tensor(2.2550, grad_fn=<NormBackward0>)\n",
            "tensor(2.4082, grad_fn=<NormBackward0>)\n",
            "tensor(4.0045, grad_fn=<NormBackward0>)\n",
            "tensor(2.6151, grad_fn=<NormBackward0>)\n",
            "tensor(5.0185, grad_fn=<NormBackward0>)\n",
            "tensor(4.5589, grad_fn=<NormBackward0>)\n",
            "tensor(3.4383, grad_fn=<NormBackward0>)\n",
            "tensor(5.0690, grad_fn=<NormBackward0>)\n",
            "tensor(3.3603, grad_fn=<NormBackward0>)\n",
            "tensor(4.4439, grad_fn=<NormBackward0>)\n",
            "tensor(2.1244, grad_fn=<NormBackward0>)\n",
            "tensor(2.6184, grad_fn=<NormBackward0>)\n",
            "tensor(2.0304, grad_fn=<NormBackward0>)\n",
            "tensor(2.7586, grad_fn=<NormBackward0>)\n",
            "tensor(3.0186, grad_fn=<NormBackward0>)\n",
            "tensor(3.2981, grad_fn=<NormBackward0>)\n",
            "tensor(2.9778, grad_fn=<NormBackward0>)\n",
            "tensor(4.7045, grad_fn=<NormBackward0>)\n",
            "tensor(2.8418, grad_fn=<NormBackward0>)\n",
            "tensor(3.9001, grad_fn=<NormBackward0>)\n",
            "tensor(4.5841, grad_fn=<NormBackward0>)\n",
            "tensor(2.1961, grad_fn=<NormBackward0>)\n",
            "tensor(3.2297, grad_fn=<NormBackward0>)\n",
            "tensor(3.6087, grad_fn=<NormBackward0>)\n",
            "tensor(1.8766, grad_fn=<NormBackward0>)\n",
            "tensor(5.2138, grad_fn=<NormBackward0>)\n",
            "tensor(2.8700, grad_fn=<NormBackward0>)\n",
            "tensor(2.1502, grad_fn=<NormBackward0>)\n",
            "tensor(3.4382, grad_fn=<NormBackward0>)\n",
            "tensor(2.9313, grad_fn=<NormBackward0>)\n",
            "tensor(3.8088, grad_fn=<NormBackward0>)\n",
            "tensor(2.3203, grad_fn=<NormBackward0>)\n",
            "tensor(2.2200, grad_fn=<NormBackward0>)\n",
            "tensor(4.5236, grad_fn=<NormBackward0>)\n",
            "tensor(2.7387, grad_fn=<NormBackward0>)\n",
            "tensor(1.4523, grad_fn=<NormBackward0>)\n",
            "tensor(2.2773, grad_fn=<NormBackward0>)\n",
            "tensor(2.8412, grad_fn=<NormBackward0>)\n",
            "tensor(3.4265, grad_fn=<NormBackward0>)\n",
            "tensor(3.1318, grad_fn=<NormBackward0>)\n",
            "tensor(3.1482, grad_fn=<NormBackward0>)\n",
            "tensor(4.1538, grad_fn=<NormBackward0>)\n",
            "tensor(4.8247, grad_fn=<NormBackward0>)\n",
            "tensor(2.1455, grad_fn=<NormBackward0>)\n",
            "tensor(2.4092, grad_fn=<NormBackward0>)\n",
            "tensor(3.1911, grad_fn=<NormBackward0>)\n",
            "tensor(4.4147, grad_fn=<NormBackward0>)\n",
            "tensor(1.1932, grad_fn=<NormBackward0>)\n",
            "tensor(3.6860, grad_fn=<NormBackward0>)\n",
            "tensor(4.2796, grad_fn=<NormBackward0>)\n",
            "tensor(2.2003, grad_fn=<NormBackward0>)\n",
            "tensor(3.4356, grad_fn=<NormBackward0>)\n",
            "tensor(3.6847, grad_fn=<NormBackward0>)\n",
            "tensor(4.1557, grad_fn=<NormBackward0>)\n",
            "tensor(2.9317, grad_fn=<NormBackward0>)\n",
            "tensor(3.2078, grad_fn=<NormBackward0>)\n",
            "tensor(3.2819, grad_fn=<NormBackward0>)\n",
            "tensor(3.7178, grad_fn=<NormBackward0>)\n",
            "tensor(3.6252, grad_fn=<NormBackward0>)\n",
            "tensor(3.6270, grad_fn=<NormBackward0>)\n",
            "tensor(3.9161, grad_fn=<NormBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}